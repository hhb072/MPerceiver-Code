from os import path as osp
from torch.utils import data as data
from torchvision.transforms.functional import normalize

from basicsr.data.data_util import paths_from_lmdb
from basicsr.utils import FileClient, imfrombytes, img2tensor, rgb2ycbcr, scandir
from basicsr.utils.registry import DATASET_REGISTRY

from pathlib import Path
import random
import cv2
import numpy as np
import torch
import math 
import time 
import os 

# @DATASET_REGISTRY.register()
class SingleImageDataset(data.Dataset):
    """Read only lq images in the test phase.

    Read LQ (Low Quality, e.g. LR (Low Resolution), blurry, noisy, etc).

    There are two modes:
    1. 'meta_info_file': Use meta information file to generate paths.
    2. 'folder': Scan folders to generate paths.

    Args:
        opt (dict): Config for train datasets. It contains the following keys:
            dataroot_lq (str): Data root path for lq.
            meta_info_file (str): Path for meta information file.
            io_backend (dict): IO backend type and other kwarg.
    """

    def __init__(self, opt):
        super(SingleImageDataset, self).__init__()
        self.opt = opt
        # file client (io backend)
        self.file_client = None
        self.io_backend_opt = opt['io_backend']
        self.mean = opt['mean'] if 'mean' in opt else None
        self.std = opt['std'] if 'std' in opt else None
        self.lq_folder = opt['dataroot_lq']

        if self.io_backend_opt['type'] == 'lmdb':
            self.io_backend_opt['db_paths'] = [self.lq_folder]
            self.io_backend_opt['client_keys'] = ['lq']
            self.paths = paths_from_lmdb(self.lq_folder)
        elif 'meta_info_file' in self.opt:
            with open(self.opt['meta_info_file'], 'r') as fin:
                self.paths = [osp.join(self.lq_folder, line.rstrip().split(' ')[0]) for line in fin]
        else:
            self.paths = sorted(list(scandir(self.lq_folder, full_path=True)))

    def __getitem__(self, index):
        if self.file_client is None:
            self.file_client = FileClient(self.io_backend_opt.pop('type'), **self.io_backend_opt)

        # load lq image
        lq_path = self.paths[index]
        img_bytes = self.file_client.get(lq_path, 'lq')
        img_lq = imfrombytes(img_bytes, float32=True)

        # color space transform
        if 'color' in self.opt and self.opt['color'] == 'y':
            img_lq = rgb2ycbcr(img_lq, y_only=True)[..., None]

        # BGR to RGB, HWC to CHW, numpy to tensor
        img_lq = img2tensor(img_lq, bgr2rgb=True, float32=True)
        # normalize
        if self.mean is not None or self.std is not None:
            normalize(img_lq, self.mean, self.std, inplace=True)
        return {'lq': img_lq, 'lq_path': lq_path}

    def __len__(self):
        return len(self.paths)

# @DATASET_REGISTRY.register()
class SingleImageNPDataset(data.Dataset):
    """Read only lq images in the test phase.

    Read diffusion generated data for training CFW.

    Args:
        opt (dict): Config for train datasets. It contains the following keys:
            gt_path: Data root path for training data. The path needs to contain the following folders:
                gts: Ground-truth images.
                inputs: Input LQ images.
                latents: The corresponding HQ latent code generated by diffusion model given the input LQ image.
                samples: The corresponding HQ image given the HQ latent code, just for verification.
            io_backend (dict): IO backend type and other kwarg.
    """

    def __init__(self, opt):
        super(SingleImageNPDataset, self).__init__()
        self.opt = opt
        # file client (io backend)
        self.file_client = None
        self.io_backend_opt = opt['io_backend']
        self.mean = opt['mean'] if 'mean' in opt else None
        self.std = opt['std'] if 'std' in opt else None
        # if 'image_type' not in opt:
        #     opt['image_type'] = 'png'

        if isinstance(opt['gt_path'], str):
            self.gt_paths = sorted([str(x) for x in Path(opt['gt_path']).glob('*')])
            self.lq_paths = sorted([str(x) for x in Path(opt['lq_path']).glob('*')])
            self.np_paths = sorted([str(x) for x in Path(opt['np_path']).glob('*')])
        else:
            self.gt_paths = sorted([str(x) for x in Path(opt['gt_path'][0]).glob('*')])
            self.lq_paths = sorted([str(x) for x in Path(opt['lq_path'][0]).glob('*')])
            self.np_paths = sorted([str(x) for x in Path(opt['np_path'][0]).glob('*')])
            if len(opt['gt_path']) > 1:
                for i in range(len(opt['gt_path'])-1):
                    self.gt_paths.extend(sorted([str(x) for x in Path(opt['gt_path'][i+1]).glob('*')]))
                    self.lq_paths.extend(sorted([str(x) for x in Path(opt['lq_path'][i+1]).glob('*')]))
                    self.np_paths.extend(sorted([str(x) for x in Path(opt['np_path'][i+1]).glob('*')]))

        assert len(self.gt_paths) == len(self.lq_paths)
        assert len(self.gt_paths) == len(self.np_paths)

    def __getitem__(self, index):
        if self.file_client is None:
            self.file_client = FileClient(self.io_backend_opt.pop('type'), **self.io_backend_opt)

        # load lq image
        lq_path = self.lq_paths[index]
        gt_path = self.gt_paths[index]
        np_path = self.np_paths[index]

        img_bytes = self.file_client.get(lq_path, 'lq')
        img_lq = imfrombytes(img_bytes, float32=True)

        img_bytes_gt = self.file_client.get(gt_path, 'gt')
        img_gt = imfrombytes(img_bytes_gt, float32=True)

        latent_np = np.load(np_path)

        # color space transform
        if 'color' in self.opt and self.opt['color'] == 'y':
            img_lq = rgb2ycbcr(img_lq, y_only=True)[..., None]
            img_gt = rgb2ycbcr(img_gt, y_only=True)[..., None]
            img_sample = rgb2ycbcr(img_sample, y_only=True)[..., None]

        # BGR to RGB, HWC to CHW, numpy to tensor
        img_lq = img2tensor(img_lq, bgr2rgb=True, float32=True)
        img_gt = img2tensor(img_gt, bgr2rgb=True, float32=True)
        latent_np = torch.from_numpy(latent_np).float()
        latent_np = latent_np.to(img_gt.device)
        # normalize
        if self.mean is not None or self.std is not None:
            normalize(img_lq, self.mean, self.std, inplace=True)
            normalize(img_gt, self.mean, self.std, inplace=True)
            normalize(img_sample, self.mean, self.std, inplace=True)
        return {'lq': img_lq, 'lq_path': lq_path, 'gt': img_gt, 'gt_path': gt_path, 'latent': latent_np, 'latent_path': np_path}

    def __len__(self):
        return len(self.gt_paths)

# @DATASET_REGISTRY.register()
class SingleImageNPDataset8(data.Dataset):
    """Read only lq images in the test phase.

    Read diffusion generated data for training CFW.

    Args:
        opt (dict): Config for train datasets. It contains the following keys:
            gt_path: Data root path for training data. The path needs to contain the following folders:
                gts: Ground-truth images.
                inputs: Input LQ images.
                latents: The corresponding HQ latent code generated by diffusion model given the input LQ image.
                samples: The corresponding HQ image given the HQ latent code, just for verification.
            io_backend (dict): IO backend type and other kwarg.
    """

    def __init__(self, opt):
        super(SingleImageNPDataset8, self).__init__()
        self.opt = opt
        self.file_client = None
        self.io_backend_opt = opt['io_backend']
        if 'crop_size' in opt:
            self.crop_size = opt['crop_size']
        else:
            self.crop_size = 512
        if 'image_type' not in opt:
            opt['image_type'] = 'png'

        # support multiple type of data: file path and meta data, remove support of lmdb
        # self.paths_gt = []
        # self.paths_lq = []

        self.fix_sample = opt['fix_sample']
        self.imgs_in = []
        self.imgs_gt = []
        self.imgs_sample = []
        self.npys = []

        in_files = os.listdir(opt["root_lq"][0])
        if self.fix_sample > len(in_files):
            # self.fix_sample = len(in_files)
            in_files = random.sample(in_files,len(in_files))
        else:
            in_files = random.sample(in_files,self.fix_sample)
        self.imgs_in.append([os.path.join(opt["root_lq"][0], k) for k in in_files])
        self.imgs_gt.append([os.path.join(opt["root_gt"][0], k) for k in in_files])
        self.imgs_sample.append([os.path.join(opt["root_sample"][0], k) for k in in_files])
        self.npys.append([os.path.join(opt["root_np"][0], os.path.splitext(k)[0]+'.npy') for k in in_files])
        len_imgs_in_1 = len(self.imgs_in[0])

        for i in range(1,len(opt["root_lq"])):
            in_files = os.listdir(opt["root_lq"][i])
            if self.fix_sample > len(in_files):
                in_files = random.sample(in_files,len(in_files))
                len_ori = len(in_files)
            else: 
                in_files = random.sample(in_files,self.fix_sample)
                len_ori = self.fix_sample
            self.imgs_in.append([os.path.join(opt["root_lq"][i], k) for k in in_files])
            self.imgs_gt.append([os.path.join(opt["root_gt"][i], k) for k in in_files])
            self.imgs_sample.append([os.path.join(opt["root_sample"][i], k) for k in in_files])
            self.npys.append([os.path.join(opt["root_np"][i], os.path.splitext(k)[0]+'.npy') for k in in_files])
            self.imgs_in[-1] = self.imgs_in[-1]*(1+ math.ceil(len_imgs_in_1/len_ori))
            self.imgs_in[-1] = self.imgs_in[-1][0:len_imgs_in_1]
            self.imgs_gt[-1] = self.imgs_gt[-1]*(1+ math.ceil(len_imgs_in_1/len_ori))
            self.imgs_gt[-1] = self.imgs_gt[-1][0:len_imgs_in_1]
            self.imgs_sample[-1] = self.imgs_sample[-1]*(1+ math.ceil(len_imgs_in_1/len_ori))
            self.imgs_sample[-1] = self.imgs_sample[-1][0:len_imgs_in_1]
            self.npys[-1] = self.npys[-1]*(1+ math.ceil(len_imgs_in_1/len_ori))
            self.npys[-1] = self.npys[-1][0:len_imgs_in_1]
            
    def __getitem__(self, index):
        if self.file_client is None:
            self.file_client = FileClient(self.io_backend_opt.pop('type'), **self.io_backend_opt)

        # img_gts = []
        # img_lqs = []
        # samples = []
        # npys_ = []
        # for i in range(len(self.imgs_in)):
        #     retry = 3
        #     gt_path = self.imgs_gt[i][index]
        #     lq_path = self.imgs_in[i][index]
        #     sample_path = self.imgs_sample[i][index]
        #     npy_path = self.npys[i][index]
        #     while retry > 0:
        #         try:
        #             img_bytes_gt = self.file_client.get(gt_path, 'gt')
        #             img_bytes_lq = self.file_client.get(lq_path, 'lq')
        #             img_bytes_sample = self.file_client.get(sample_path, 'sample')
        #         except (IOError, OSError) as e:
        #             # logger = get_root_logger()
        #             # logger.warn(f'File client error: {e}, remaining retry times: {retry - 1}')
        #             # change another file to read
        #             index = random.randint(0, self.__len__()-1)
        #             gt_path = self.imgs_gt[i][index]
        #             lq_path = self.imgs_in[i][index]
        #             sample_path = self.imgs_sample[i][index]
        #             time.sleep(1)  # sleep 1s for occasional server congestion
        #         else:
        #             break
        #         finally:
        #             retry -= 1
        #     img_gts.append(imfrombytes(img_bytes_gt, float32=True))
        #     img_lqs.append(imfrombytes(img_bytes_lq, float32=True))
        #     samples.append(imfrombytes(img_bytes_sample, float32=True))
        #     npys_.append(np.load(npy_path))
        i = random.randint(0, len(self.imgs_in)-1)
        retry = 3
        gt_path = self.imgs_gt[i][index]
        lq_path = self.imgs_in[i][index]
        sample_path = self.imgs_sample[i][index]
        npy_path = self.npys[i][index]
        while retry > 0:
            try:
                img_bytes_gt = self.file_client.get(gt_path, 'gt')
                img_bytes_lq = self.file_client.get(lq_path, 'lq')
                img_bytes_sample = self.file_client.get(sample_path, 'sample')
            except (IOError, OSError) as e:
                # logger = get_root_logger()
                # logger.warn(f'File client error: {e}, remaining retry times: {retry - 1}')
                # change another file to read
                index = random.randint(0, self.__len__()-1)
                gt_path = self.imgs_gt[i][index]
                lq_path = self.imgs_in[i][index]
                sample_path = self.imgs_sample[i][index]
                time.sleep(1)
            else:
                break
            finally:
                retry -= 1
        img_gt = imfrombytes(img_bytes_gt, float32=True)
        img_lq = imfrombytes(img_bytes_lq, float32=True)
        sample = imfrombytes(img_bytes_sample, float32=True)
        npy_ = np.load(npy_path)
        
        # img_gts = [cv2.resize(img,(512,512),cv2.INTER_CUBIC) for img in img_gts]
        # img_gts = img2tensor(img_gts, bgr2rgb=True, float32=True)
        
        # samples = img2tensor(samples, bgr2rgb=True, float32=True)
        # img_gt = cv2.resize(img_gt,(512,512),cv2.INTER_CUBIC)
        img_gt = img2tensor(img_gt, bgr2rgb=True, float32=True)
        sample = img2tensor(sample, bgr2rgb=True, float32=True)
        import torchvision.transforms as transforms
        from torchvision.transforms import InterpolationMode
        def tf(x):
            x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)
            x = cv2.resize(x, (224,224), interpolation=cv2.INTER_CUBIC)
            x = transforms.ToTensor()(x)
            x = transforms.Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711))(x)
            return x
        img_lq_clip = tf(img_lq)
        # img_lqs = [cv2.resize(img,(512,512),cv2.INTER_CUBIC) for img in img_lqs]
        # img_lqs = img2tensor(img_lqs, bgr2rgb=True, float32=True)
        # img_lq = cv2.resize(img_lq,(512,512),cv2.INTER_CUBIC)
        img_lq = img2tensor(img_lq, bgr2rgb=True, float32=True)
        # npys_ = [torch.from_numpy(npy).float() for npy in npys_]
        npy_ = torch.from_numpy(npy_).float()
        # img_gts = [img.unsqueeze(0) for img in img_gts]
        # img_gts = torch.cat(img_gts,dim=0)
        # img_lqs = [img.unsqueeze(0) for img in img_lqs]
        # img_lqs = torch.cat(img_lqs,dim=0)
        # img_lqs_clip = [img.unsqueeze(0) for img in img_lqs_clip]
        # img_lqs_clip = torch.cat(img_lqs_clip,dim=0)
        # samples = [img.unsqueeze(0) for img in samples]
        # samples = torch.cat(samples,dim=0)
        # npys_ = [npy.unsqueeze(0) for npy in npys_]
        # npys_ = torch.cat(npys_,dim=0)
        # import random
        # if random.random() > 0.5:
        #     img_lqs =img_lqs[0:4,:,:,:]
        #     img_lqs_clip =img_lqs_clip[0:4,:,:,:]
        #     img_gts =img_gts[0:4,:,:,:]
        #     samples =samples[0:4,:,:,:]
        #     npys_ =npys_[0:4,:,:,:]
        # else:
        #     img_lqs =img_lqs[4:,:,:,:]
        #     img_lqs_clip =img_lqs_clip[4:,:,:,:]
        #     img_gts =img_gts[4:,:,:,:]
        #     samples =samples[4:,:,:,:]
        #     npys_ =npys_[4:,:,:,:]
        # # load lq image
        # lq_path = self.lq_paths[index]
        # gt_path = self.gt_paths[index]
        # np_path = self.np_paths[index]

        # img_bytes = self.file_client.get(lq_path, 'lq')
        # img_lq = imfrombytes(img_bytes, float32=True)

        # img_bytes_gt = self.file_client.get(gt_path, 'gt')
        # img_gt = imfrombytes(img_bytes_gt, float32=True)

        # latent_np = np.load(np_path)

        # # color space transform
        # if 'color' in self.opt and self.opt['color'] == 'y':
        #     img_lq = rgb2ycbcr(img_lq, y_only=True)[..., None]
        #     img_gt = rgb2ycbcr(img_gt, y_only=True)[..., None]
        #     img_sample = rgb2ycbcr(img_sample, y_only=True)[..., None]

        # # BGR to RGB, HWC to CHW, numpy to tensor
        # img_lq = img2tensor(img_lq, bgr2rgb=True, float32=True)
        # img_gt = img2tensor(img_gt, bgr2rgb=True, float32=True)
        # latent_np = torch.from_numpy(latent_np).float()
        # latent_np = latent_np.to(img_gt.device)
        # # normalize
        # if self.mean is not None or self.std is not None:
        #     normalize(img_lq, self.mean, self.std, inplace=True)
        #     normalize(img_gt, self.mean, self.std, inplace=True)
        #     normalize(img_sample, self.mean, self.std, inplace=True)
        return {'lq': img_lq, 'gt': img_gt,'lq_clip':img_lq_clip, 'latent': npy_, 'sample': sample}

    def __len__(self):
        return len(self.imgs_in[0])
